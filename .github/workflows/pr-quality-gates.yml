name: PR Quality Gates

on:
  pull_request:
    branches: 
      - copilot
      - development
      - staging
      - production
    types: [opened, synchronize, reopened]

  # Allow manual trigger for testing
  workflow_dispatch:

env:
  DOTNET_VERSION: '9.0.102'
  DOCKER_BUILDKIT: 1

jobs:
  # Job 1: Static Analysis & Code Scanning
  static-analysis:
    name: Static Analysis & Code Scanning
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      security-events: write
      actions: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Restore dependencies
        run: dotnet restore AgentAsAService.sln
      
      - name: Build solution
        run: dotnet build AgentAsAService.sln --no-restore --configuration Release /p:RunAnalyzersDuringBuild=true /p:TreatWarningsAsErrors=false
      
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: csharp
          config: |
            paths-ignore:
              - '**/bin/**'
              - '**/obj/**'
              - '**/publish/**'
      
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:csharp"

  # Job 2: Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      security-events: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Restore dependencies
        run: dotnet restore AgentAsAService.sln
      
      - name: Run Security Scan with Semgrep
        uses: semgrep/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/csharp
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
      
      - name: Dependency Vulnerability Scan
        run: |
          dotnet list package --vulnerable --include-transitive 2>&1 | tee vulnerability-report.txt
          if grep -q "has the following vulnerable packages" vulnerability-report.txt; then
            echo "❌ Vulnerable dependencies found!"
            cat vulnerability-report.txt
            exit 1
          else
            echo "✅ No vulnerable dependencies found"
          fi

  # Job 3: Docker Image Scanning
  docker-scan:
    name: Docker Image Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build OrchestratorService Docker image
        run: |
          docker build -t orchestratorservice:scan -f OrchestratorService/Dockerfile .
      
      - name: Build AgentService Docker image
        run: |
          docker build -t agentservice:scan -f AgentService/Dockerfile .
      
      - name: Run Trivy vulnerability scanner - OrchestratorService
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'orchestratorservice:scan'
          format: 'sarif'
          output: 'orchestrator-trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'
      
      - name: Run Trivy vulnerability scanner - AgentService
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'agentservice:scan'
          format: 'sarif'
          output: 'agent-trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'
      
      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: |
            orchestrator-trivy-results.sarif
            agent-trivy-results.sarif

  # Job 4: Automated Testing
  automated-testing:
    name: Automated Testing
    runs-on: ubuntu-latest
    
    services:
      # Add any required services (Redis, SQL Server, etc.)
      redis:
        image: redis:alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Restore dependencies
        run: dotnet restore AgentAsAService.sln
      
      - name: Build solution
        run: dotnet build AgentAsAService.sln --no-restore --configuration Release
      
      - name: Run unit tests
        id: test-run
        continue-on-error: true
        run: |
          dotnet test AgentAsAService.sln \
            --no-build \
            --configuration Release \
            --verbosity normal \
            --collect:"XPlat Code Coverage" \
            --results-directory ./coverage \
            --logger trx \
            --logger "console;verbosity=detailed"
      
      - name: Generate code coverage report
        uses: danielpalme/ReportGenerator-GitHub-Action@5.2.0
        if: always()  # Generate coverage report even if tests failed
        with:
          reports: 'coverage/**/coverage.cobertura.xml'
          targetdir: 'coverage-report'
          reporttypes: 'Html;Cobertura;MarkdownSummaryGithub'
      
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()  # Upload reports even if tests failed
        with:
          name: coverage-report
          path: coverage-report/
      
      - name: Comment coverage on PR
        uses: marocchino/sticky-pull-request-comment@v2
        if: always() && github.event_name == 'pull_request'  # Comment even if tests failed
        with:
          recreate: true
          path: coverage-report/SummaryGithub.md
      
      - name: Check test results
        if: steps.test-run.outcome == 'failure'
        run: |
          echo "❌ Unit tests failed! Check the test results above."
          echo "Coverage reports have been generated for debugging."
          exit 1

  # Job 5: Integration Tests (if applicable)
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [static-analysis, automated-testing]
    
    services:
      # Firebase Emulator or other integration test services
      firestore-emulator:
        image: google/cloud-sdk:alpine
        ports:
          - 8080:8080
        options: >-
          --health-cmd "curl -f http://localhost:8080 || exit 1"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 3
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Start Firebase Emulators
        run: |
          # Install Firebase CLI
          npm install -g firebase-tools
          
          # Start emulators in background
          firebase emulators:start --only firestore,auth --project demo-test &
          
          # Wait for emulators to be ready
          timeout=30
          while [ $timeout -gt 0 ]; do
            if curl -f http://localhost:8080; then
              echo "✅ Firebase emulators ready"
              break
            fi
            sleep 1
            ((timeout--))
          done
        
      - name: Run integration tests
        run: |
          dotnet test AgentAsAService.sln \
            --filter Category=Integration \
            --configuration Release \
            --verbosity normal \
            --logger "console;verbosity=detailed"
        env:
          FIRESTORE_EMULATOR_HOST: localhost:8080
          FIREBASE_AUTH_EMULATOR_HOST: localhost:9099

  # Job 6: Final Quality Gate
  quality-gate:
    name: Quality Gate Summary
    runs-on: ubuntu-latest
    needs: [static-analysis, security-scan, docker-scan, automated-testing, integration-tests]
    if: always()
    
    steps:
      - name: Check all jobs status
        run: |
          echo "Quality Gate Results:"
          echo "- Static Analysis: ${{ needs.static-analysis.result }}"
          echo "- Security Scan: ${{ needs.security-scan.result }}"
          echo "- Docker Scan: ${{ needs.docker-scan.result }}"
          echo "- Automated Testing: ${{ needs.automated-testing.result }}"
          echo "- Integration Tests: ${{ needs.integration-tests.result }}"
          
          if [[ "${{ needs.static-analysis.result }}" == "success" && \
                "${{ needs.security-scan.result }}" == "success" && \
                "${{ needs.docker-scan.result }}" == "success" && \
                "${{ needs.automated-testing.result }}" == "success" && \
                "${{ needs.integration-tests.result }}" == "success" ]]; then
            echo "✅ All quality gates passed! PR is ready for review."
            exit 0
          else
            echo "❌ One or more quality gates failed. PR cannot be merged."
            exit 1
          fi
